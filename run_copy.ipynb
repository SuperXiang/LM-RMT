{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dfb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('pytorch')\n",
    "sys.path.append('pytorch/utils')\n",
    "\n",
    "from pytorch.mem_transformer import *\n",
    "from pytorch import data_utils\n",
    "\n",
    "from experiment_utils.run_experiment import *\n",
    "from experiment_utils.generate_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e6986",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de49706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "TAG = '10tkn_len24_ext'\n",
    "\n",
    "TASK_NAME = 'copy'\n",
    "TRAIN_SIZE = 100_000\n",
    "VAL_SIZE = 2_000\n",
    "TEST_SIZE = 10_000\n",
    "NUM_INITS = 1\n",
    "\n",
    "\n",
    "NUM_BATCHES = int(4e5)\n",
    "BATCH_SIZE = 128\n",
    "GENERATE_EVERY  = 10000\n",
    "NUM_TOKENS = 10 + 2\n",
    "ENC_SEQ_LEN = 24\n",
    "DEC_SEQ_LEN = 48\n",
    "\n",
    "INPUT_LEN = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87cb25",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b7097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "# generator = copy_generator(batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN, num_tokens=NUM_TOKENS)\n",
    "# generate_data(generator, path=f'data{INPUT_LEN}', task_name=TASK_NAME, train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE, batch_size=BATCH_SIZE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17253635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader:\n",
    "    def __init__(self, task_name, path='data', batch_size=32, none_mask=True):\n",
    "        self.X, self.y = np.load(f'{path}/{task_name}_X.npy'), np.load(f'{path}/{task_name}_y.npy')\n",
    "        self.data_size = self.X.shape[0]\n",
    "        self.data_ptr = 0\n",
    "\n",
    "        if none_mask:\n",
    "            self.src_mask, self.tgt_mask = None, None\n",
    "        else:\n",
    "            self.src_masks, self.tgt_mask = np.load(f'{path}/{task_name}_mask.npy'), None\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.none_mask = none_mask\n",
    "\n",
    "    def __next__(self):\n",
    "        X = self.X[self.data_ptr: self.data_ptr+self.batch_size]\n",
    "        y = self.y[self.data_ptr: self.data_ptr+self.batch_size]\n",
    "        \n",
    "        if not self.none_mask:\n",
    "            sm = self.src_masks[self.data_ptr: self.data_ptr+self.batch_size]\n",
    "            sm = torch.tensor(sm).cuda()\n",
    "        else:\n",
    "            sm = None\n",
    "            \n",
    "        self.data_ptr = (self.data_ptr + self.batch_size) % self.data_size\n",
    "\n",
    "        return torch.tensor(X),\\\n",
    "                torch.tensor(y),\\\n",
    "                sm, self.tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c118128",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "082c59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = ParameterGrid({\n",
    "                'n_layer': [2],\n",
    "                'n_head': [4],\n",
    "                'd_head': [128],\n",
    "                'num_mem_tokens': [9, 0], \n",
    "                'mem_len': [0]})\n",
    "\n",
    "param = list(model_parameters)[0]\n",
    "\n",
    "fixed_parameters = {'n_token': NUM_TOKENS,\n",
    "                    'd_model': param['d_head'],# + param['num_mem_tokens']-1,\n",
    "                    'd_inner': param['d_head'],\n",
    "                    'dropout': 0,\n",
    "                    'dropatt': 0,\n",
    "                    'tie_weight': True,\n",
    "                    'div_val': 1, # ???????\n",
    "                    'tie_projs': [False],\n",
    "                    'tgt_len': DEC_SEQ_LEN,\n",
    "                    'ext_len': 0, \n",
    "                    'cutoffs': [],\n",
    "                    'attn_type': 0,}\n",
    "\n",
    "model = MemTransformerLM(**param, **fixed_parameters)#.cuda()\n",
    "\n",
    "gen_train = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE)\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "# src, tgt = src.cuda(), tgt.cuda()\n",
    "src, tgt = src.cpu(), tgt.cpu()\n",
    "\n",
    "mems = tuple()\n",
    "# model(src.cpu(), tgt.cpu(), *mems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "467618bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep = src[0].repeat(16, 1)\n",
    "# hidden, new_mems = model._forward(rep)\n",
    "\n",
    "mems = None\n",
    "# dec_inp = src[0].repeat(21, 1).T\n",
    "dec_inp = src[:21].T\n",
    "self = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa644df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_emb = self.word_emb(dec_inp)\n",
    "\n",
    "mlen = mems[0].size(0) if mems is not None else 0\n",
    "\n",
    "# Concat with mem_tokens\n",
    "if self.num_mem_tokens not in (0, None):\n",
    "    # memory = self.mem_tokens.repeat(1, dec_inp.shape[0], 1).clone()\n",
    "    memory = self.mem_tokens.reshape(self.num_mem_tokens, 1, -1).repeat(1, dec_inp.shape[1], 1)\n",
    "    word_emb = torch.cat((memory, word_emb), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f6344ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayd98/Desktop/MIPT/TXL/pytorch/mem_transformer.py:267: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n",
      "  attn_score = attn_score.float().masked_fill(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# qlen, bsz = dec_inp.size()\n",
    "qlen = word_emb.shape[0]\n",
    "klen = mlen + qlen\n",
    "if self.same_length:\n",
    "    all_ones = word_emb.new_ones(qlen, klen)\n",
    "    mask_len = klen - self.mem_len\n",
    "    if mask_len > 0:\n",
    "        mask_shift_len = qlen - mask_len\n",
    "    else:\n",
    "        mask_shift_len = qlen\n",
    "    dec_attn_mask = (torch.triu(all_ones, 1+mlen)\n",
    "            + torch.tril(all_ones, -mask_shift_len)).byte()[:, :, None] # -1\n",
    "else:\n",
    "    dec_attn_mask = torch.triu(\n",
    "        word_emb.new_ones(qlen, klen), diagonal=1+mlen).byte()[:,:,None]\n",
    "\n",
    "hids = []\n",
    "if self.attn_type == 0: # default\n",
    "    pos_seq = torch.arange(klen-1, -1, -1.0, device=word_emb.device, \n",
    "                            dtype=word_emb.dtype)\n",
    "    if self.clamp_len > 0:\n",
    "        pos_seq.clamp_(max=self.clamp_len)\n",
    "    pos_emb = self.pos_emb(pos_seq)\n",
    "\n",
    "    core_out = self.drop(word_emb)\n",
    "    pos_emb = self.drop(pos_emb)\n",
    "\n",
    "    hids.append(core_out)\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        mems_i = None if mems is None else mems[i]\n",
    "        core_out = layer(core_out, pos_emb, self.r_w_bias,\n",
    "                self.r_r_bias, dec_attn_mask=dec_attn_mask, mems=mems_i)\n",
    "        hids.append(core_out)\n",
    "elif self.attn_type == 1: # learnable\n",
    "    core_out = self.drop(word_emb)\n",
    "    hids.append(core_out)\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        if self.clamp_len > 0:\n",
    "            r_emb = self.r_emb[i][-self.clamp_len :]\n",
    "            r_bias = self.r_bias[i][-self.clamp_len :]\n",
    "        else:\n",
    "            r_emb, r_bias = self.r_emb[i], self.r_bias[i]\n",
    "\n",
    "        mems_i = None if mems is None else mems[i]\n",
    "        core_out = layer(core_out, r_emb, self.r_w_bias[i],\n",
    "                r_bias, dec_attn_mask=dec_attn_mask, mems=mems_i)\n",
    "        hids.append(core_out)\n",
    "elif self.attn_type == 2: # absolute\n",
    "    pos_seq = torch.arange(klen - 1, -1, -1.0, device=word_emb.device,\n",
    "                            dtype=word_emb.dtype)\n",
    "    if self.clamp_len > 0:\n",
    "        pos_seq.clamp_(max=self.clamp_len)\n",
    "    pos_emb = self.pos_emb(pos_seq)\n",
    "\n",
    "    core_out = self.drop(word_emb + pos_emb[-qlen:])\n",
    "\n",
    "    hids.append(core_out)\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        mems_i = None if mems is None else mems[i]\n",
    "        if mems_i is not None and i == 0:\n",
    "            mems_i += pos_emb[:mlen]\n",
    "        core_out = layer(core_out, dec_attn_mask=dec_attn_mask,\n",
    "                            mems=mems_i)\n",
    "        hids.append(core_out)\n",
    "elif self.attn_type == 3:\n",
    "    core_out = self.drop(word_emb)\n",
    "\n",
    "    hids.append(core_out)\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        mems_i = None if mems is None else mems[i]\n",
    "        if mems_i is not None and mlen > 0:\n",
    "            cur_emb = self.r_emb[i][:-qlen]\n",
    "            cur_size = cur_emb.size(0)\n",
    "            if cur_size < mlen:\n",
    "                cur_emb_pad = cur_emb[0:1].expand(mlen-cur_size, -1, -1)\n",
    "                cur_emb = torch.cat([cur_emb_pad, cur_emb], 0)\n",
    "            else:\n",
    "                cur_emb = cur_emb[-mlen:]\n",
    "            mems_i += cur_emb.view(mlen, 1, -1)\n",
    "        core_out += self.r_emb[i][-qlen:].view(qlen, 1, -1)\n",
    "\n",
    "        core_out = layer(core_out, dec_attn_mask=dec_attn_mask,\n",
    "                            mems=mems_i)\n",
    "        hids.append(core_out)\n",
    "\n",
    "core_out = self.drop(core_out)\n",
    "\n",
    "new_mems = self._update_mems(hids, mems, mlen, qlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f41dcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4e7cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 21])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6d4d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 128])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07574902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 21, 128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "991e37d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 21, 128]), tensor(0))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_out.shape, core_out.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20f52202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0](hids[0],pos_emb,  self.r_w_bias,\n",
    "#                 self.r_r_bias, dec_attn_mask=dec_attn_mask, mems=mems_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "421835d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7908edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 33, 33)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlen, qlen, klen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4332142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 1, 128]), torch.Size([33]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb.shape, pos_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69f7b596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 21, 128]),\n",
       " tensor([[[-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          ...,\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878]],\n",
       " \n",
       "         [[-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          ...,\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878]],\n",
       " \n",
       "         [[-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          ...,\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878],\n",
       "          [-0.7845,  0.5875, -1.3231,  ..., -1.7092, -1.0594, -0.4878]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.4944,  1.5785, -0.1348,  ...,  1.2145,  0.1253, -2.1817],\n",
       "          [-2.5041,  1.8835, -0.2962,  ...,  1.4935,  0.1486, -2.3502],\n",
       "          [ 1.3503,  0.3094,  0.1640,  ...,  0.9336, -0.9942, -0.6886],\n",
       "          ...,\n",
       "          [-0.9251,  0.6232, -1.0443,  ...,  0.9003, -1.5739, -1.6132],\n",
       "          [ 1.4714, -0.8434, -2.0946,  ...,  0.3871, -0.6039,  0.7107],\n",
       "          [-1.6745,  0.2229, -0.4746,  ...,  0.3722, -0.8961, -0.8928]],\n",
       " \n",
       "         [[ 0.4745, -0.6301, -1.6059,  ...,  0.2265, -2.1857, -0.5656],\n",
       "          [ 0.2481,  0.9250, -0.0194,  ...,  0.4710, -1.4282,  1.0343],\n",
       "          [ 0.4096, -0.3540, -1.5199,  ...,  0.1721, -2.0124, -0.6108],\n",
       "          ...,\n",
       "          [-0.9205,  0.7823, -0.9939,  ...,  0.6101, -1.6531, -1.4092],\n",
       "          [-0.5570,  0.6949, -0.8869,  ...,  1.3227, -0.5563, -0.7415],\n",
       "          [ 0.3722, -0.6217, -1.5523,  ...,  0.1863, -1.9039, -0.3110]],\n",
       " \n",
       "         [[ 1.1925, -0.0075,  0.0913,  ...,  0.7208, -0.8636, -0.7027],\n",
       "          [-1.7283,  0.5369, -0.7409,  ...,  0.6624, -0.6998, -1.1719],\n",
       "          [-1.0123,  0.7180, -0.2009,  ...,  1.2342, -1.6591, -0.9191],\n",
       "          ...,\n",
       "          [-2.0900,  0.7771, -1.0910,  ...,  0.4421, -0.6744, -1.0893],\n",
       "          [-0.6612,  2.1586,  1.1981,  ..., -0.9184, -0.9821,  0.8030],\n",
       "          [-1.3190,  0.5777, -0.1509,  ...,  1.3998, -1.4616, -1.0731]]],\n",
       "        grad_fn=<NativeLayerNormBackward>))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_out.shape, core_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4588e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1921e-07,  1.7881e-07, -1.1921e-07, -3.5763e-07,  1.0431e-07,\n",
       "        -1.7881e-07,  0.0000e+00,  5.9605e-08, -2.3842e-07, -2.3842e-07,\n",
       "         1.7136e-07, -3.5763e-07,  2.3842e-07,  8.1956e-08,  0.0000e+00,\n",
       "        -5.9605e-08,  2.3842e-07,  5.9605e-08, -2.9802e-08, -2.9802e-07,\n",
       "        -2.9802e-07,  1.1921e-07, -1.1921e-07,  2.9802e-08,  1.8626e-08,\n",
       "         6.7055e-08, -2.3842e-07,  1.0431e-07, -2.3842e-07,  0.0000e+00,\n",
       "         1.7881e-07,  1.3411e-07, -8.1956e-08, -2.9802e-08, -1.7881e-07,\n",
       "        -1.1921e-07, -2.9802e-08, -2.9802e-07,  2.9802e-08,  0.0000e+00,\n",
       "         1.1921e-07,  2.3842e-07, -2.3842e-07, -5.9605e-08,  1.1921e-07,\n",
       "        -1.6391e-07,  2.3842e-07, -3.5763e-07,  2.3842e-07, -2.9802e-08,\n",
       "         8.9407e-08,  2.9802e-08,  8.9407e-08,  1.1921e-07, -1.3411e-07,\n",
       "        -8.9407e-08,  0.0000e+00, -5.9605e-08, -4.7684e-07,  0.0000e+00,\n",
       "        -1.1921e-07, -2.3842e-07,  1.4901e-07,  0.0000e+00, -2.3842e-07,\n",
       "        -2.3842e-07, -1.1921e-07,  1.1921e-07,  2.9802e-07, -1.0245e-07,\n",
       "         3.5763e-07, -3.5763e-07,  2.3842e-07,  5.9605e-08,  2.3842e-07,\n",
       "         2.3842e-07,  1.7881e-07, -1.1921e-07, -1.1921e-07, -5.9605e-08,\n",
       "        -1.1921e-07, -8.9407e-08,  1.1921e-07,  1.1921e-07, -2.3842e-07,\n",
       "        -2.9802e-08, -1.1921e-07,  1.1176e-07, -5.9605e-08,  1.1921e-07,\n",
       "        -8.9407e-08,  1.1921e-07,  1.1921e-07, -1.4901e-07,  3.7253e-08,\n",
       "         7.4506e-08,  1.1921e-07,  1.4901e-08,  2.9802e-08,  0.0000e+00,\n",
       "        -2.0862e-07,  2.3842e-07,  1.6764e-08, -1.4901e-07, -2.3842e-07,\n",
       "        -2.6822e-07,  2.9802e-08,  0.0000e+00, -5.9605e-08,  1.1921e-07,\n",
       "         1.1921e-07, -3.5763e-07, -1.1921e-07,  2.3842e-07, -5.9605e-08,\n",
       "        -5.9605e-08,  1.1921e-07,  5.9605e-08,  7.4506e-08,  5.9605e-08,\n",
       "         0.0000e+00, -9.6858e-08, -7.4506e-09,  2.3842e-07, -2.3842e-07,\n",
       "        -2.3842e-07,  0.0000e+00,  0.0000e+00], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_out[0][0] - core_out[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36f49f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5514,  0.5341, -0.9070,  ...,  1.0000,  1.0000,  1.0000]],\n",
       "\n",
       "        [[-0.4040,  0.9900, -0.9507,  ...,  1.0000,  1.0000,  1.0000]],\n",
       "\n",
       "        [[-0.9880,  0.7488, -0.4844,  ...,  1.0000,  1.0000,  1.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9093,  0.9870,  0.9975,  ...,  1.0000,  1.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.7617,  0.6816,  ...,  1.0000,  1.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b25c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_out[:, 0] - core_out[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07835a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0][0] - hidden[0][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7472a74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6850, -0.5999, -0.9625,  ...,  0.8854, -0.2791,  0.3821],\n",
       "        [ 0.6850, -0.5999, -0.9625,  ...,  0.8854, -0.2791,  0.3821],\n",
       "        [ 0.6850, -0.5999, -0.9625,  ...,  0.8854, -0.2791,  0.3821],\n",
       "        ...,\n",
       "        [-0.6816,  0.3168,  2.0647,  ..., -0.2411,  0.9336, -0.9197],\n",
       "        [-1.6048, -1.4270, -0.2114,  ...,  0.3779,  0.5680,  1.2500],\n",
       "        [-0.8432, -0.6461, -0.9086,  ..., -0.2625, -0.3066, -1.0324]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a701a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(nn.Module):\n",
    "    def __init__(self, enc_kwargs, dec_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Encoder = MemTransformerLM(**enc_kwargs)\n",
    "        self.Decoder = MemTransformerLM(**dec_kwargs)\n",
    "\n",
    "        self.enc_kwargs = enc_kwargs\n",
    "        self.dec_kwargs = dec_kwargs\n",
    "\n",
    "    def forward(self, src, tgt, mems=None):\n",
    "        hidden, mems = self.Encoder(src, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472b17bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e75684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 128]), torch.Size([2, 24, 128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mem_tokens.shape, model.mem_tokens.repeat(2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd81ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 24]), torch.Size([128, 49]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape, tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5783f4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): RelPartialLearnableDecoderLayer(\n",
       "    (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "      (qkv_net): Linear(in_features=128, out_features=1536, bias=False)\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (dropatt): Dropout(p=0, inplace=False)\n",
       "      (o_net): Linear(in_features=512, out_features=128, bias=False)\n",
       "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (r_net): Linear(in_features=128, out_features=512, bias=False)\n",
       "    )\n",
       "    (pos_ff): PositionwiseFF(\n",
       "      (CoreNet): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RelPartialLearnableDecoderLayer(\n",
       "    (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "      (qkv_net): Linear(in_features=128, out_features=1536, bias=False)\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (dropatt): Dropout(p=0, inplace=False)\n",
       "      (o_net): Linear(in_features=512, out_features=128, bias=False)\n",
       "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (r_net): Linear(in_features=128, out_features=512, bias=False)\n",
       "    )\n",
       "    (pos_ff): PositionwiseFF(\n",
       "      (CoreNet): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e14d2799",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-e37bbd9dfcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cudaenv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-7730794f37c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, target, *mems)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mtgt_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mpred_hid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-7730794f37c9>\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, dec_inp, mems)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0mmlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;31m# Concat with mem_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model(src, tgt, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596b1aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-948876bfd8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'src' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "src.shape, src.repeat((1, 1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db167db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e975a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  3\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0007\n",
    "\n",
    "model_parameters = ParameterGrid({'dim': [128],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [NUM_TOKENS],\n",
    "    'depth,heads': [(2, 4)],\n",
    "    'enc_max_seq_len': [24],\n",
    "    'dec_num_tokens': [NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [2, 8, 0]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92978633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: "
     ]
    }
   ],
   "source": [
    "gen_train = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE)\n",
    "gen_val = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE)\n",
    "gen_test = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE)\n",
    "\n",
    "\n",
    "print_file = f'logs/{TASK_NAME}_{TAG}_memory_logs.txt'\n",
    "t = time.time()\n",
    "with torch.cuda.device(0):\n",
    "    for init_num in range(NUM_INITS):\n",
    "        with open(print_file, 'a') as f:\n",
    "            f.write('\\n\\nInit number ' + str(init_num)+'\\n')\n",
    "        for i, param in enumerate(list(model_parameters)):\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write('\\n\\n' + str(param)+'\\n')\n",
    "            param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "            param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "            param.pop('depth,heads')\n",
    "\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'{i / len(model_parameters) * 100}%')\n",
    "            model = TransformerXL\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_{TAG}_v{init_num}\"\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            train_validate_model(model, \n",
    "                            train_generator=gen_train, \n",
    "                            val_generator=gen_val, \n",
    "                            optim=optim, \n",
    "                            model_name=model_name, \n",
    "                            config=param,\n",
    "                            num_batches=NUM_BATCHES,\n",
    "                            generate_every=GENERATE_EVERY,\n",
    "                            print_file=print_file,\n",
    "                            tag=TAG,\n",
    "                            overfit_stop=False)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG)\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
    "            t = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
